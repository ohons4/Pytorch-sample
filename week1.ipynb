{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b7c576d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1.])\n",
      "tensor(1.)\n",
      "1.0\n",
      "tensor([1., 1., 2.])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "a = torch.ones(3)\n",
    "print(a)\n",
    "print(a[0])\n",
    "print(float(a[1]))\n",
    "a[2] = 2.0\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9e9d601",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 0., 0., 0.])\n",
      "tensor([4., 1., 5., 3., 2., 1.])\n"
     ]
    }
   ],
   "source": [
    "points = torch.zeros(6)\n",
    "print(points)\n",
    "points[0] = 4.0\n",
    "points[1] = 1.0\n",
    "points[2] = 5.0\n",
    "points[3] = 3.0\n",
    "points[4] = 2.0\n",
    "points[5] = 1.0\n",
    "print(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "00f74e3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4., 1., 5., 3., 2., 1.])\n"
     ]
    }
   ],
   "source": [
    "points = torch.tensor([4.0, 1.0, 5.0, 3.0, 2.0, 1.0])\n",
    "print(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f4fbe46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4., 1.],\n",
      "        [5., 3.],\n",
      "        [2., 1.]])\n",
      "torch.Size([3, 2])\n",
      "tensor([4., 1.])\n",
      "tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "points = torch.tensor([[4.0, 1.0], [5.0, 3.0], [2.0, 1.0]])\n",
    "print(points)\n",
    "print(points.shape)\n",
    "print(points[0]) # 0番目の２次元座標を取得できる\n",
    "print(points[2, 1]) # 2番目のY座標を取得できる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a6b53009",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[5., 3.],\n",
      "        [2., 1.]])\n",
      "tensor([[5., 3.],\n",
      "        [2., 1.]])\n",
      "tensor([5., 2.])\n",
      "tensor([[[4., 1.],\n",
      "         [5., 3.],\n",
      "         [2., 1.]]])\n"
     ]
    }
   ],
   "source": [
    "points = torch.tensor([[4.0, 1.0], [5.0, 3.0], [2.0, 1.0]])\n",
    "print(points[1:]) # 行1位校を指定、暗に列も全部指定\n",
    "print(points[1: , :]) # 行1以降を指定、明に列も全部指定\n",
    "print(points[1: , 0]) # 行1以降で列0をすべて指定\n",
    "print(points[None]) # 新たな次元を追加"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "99ce346b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.2126, 0.7152, 0.0722], names=('channels',))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4646/1677095449.py:1: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at ../c10/core/TensorImpl.h:1928.)\n",
      "  weights_names = torch.tensor([0.2126, 0.7152, 0.0722], names=['channels'])\n"
     ]
    }
   ],
   "source": [
    "weights_names = torch.tensor([0.2126, 0.7152, 0.0722], names=['channels'])\n",
    "print(weights_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ad6600f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img_named:  torch.Size([3, 5, 5]) ('channels', 'row', 'columns')\n",
      "batch_named:  torch.Size([2, 3, 5, 5]) (None, 'channels', 'row', 'columns')\n"
     ]
    }
   ],
   "source": [
    "# ちょいよくわからん\n",
    "img_t = torch.randn(3, 5, 5)\n",
    "weights = torch.tensor([0.2126, 0.7152, 0.0722])\n",
    "batch_t = torch.randn(2, 3, 5, 5)\n",
    "\n",
    "img_named = img_t.refine_names(..., 'channels', 'row', 'columns')\n",
    "batch_named = batch_t.refine_names(..., 'channels', 'row', 'columns')\n",
    "print(\"img_named: \", img_named.shape, img_named.names)\n",
    "print(\"batch_named: \", batch_named.shape, batch_named.names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "39446f74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights_names: torch.Size([3]) None\n",
      "weights_aligned: torch.Size([3, 1, 1]) ('channels', 'row', 'columns')\n",
      "tensor([[[0.2126]],\n",
      "\n",
      "        [[0.7152]],\n",
      "\n",
      "        [[0.0722]]], names=('channels', 'row', 'columns'))\n"
     ]
    }
   ],
   "source": [
    "print('weights_names:', weights_names.shape, weights_names.name)\n",
    "\n",
    "weights_aligned = weights_names.align_as(img_named)\n",
    "print('weights_aligned:', weights_aligned.shape, weights_aligned.names)\n",
    "print(weights_aligned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cf317a22-804f-4d8a-92b9-de5579680f42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.]], dtype=torch.float64)\n",
      "tensor([[1, 2],\n",
      "        [3, 4]], dtype=torch.int16)\n"
     ]
    }
   ],
   "source": [
    "double_points = torch.ones(10, 2, dtype=torch.double)\n",
    "short_points = torch.tensor([[1, 2], [3, 4]], dtype=torch.short)\n",
    "\n",
    "print(double_points)\n",
    "print(short_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c14152fb-8638-4eb3-8847-a78fb773fb75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "double_points:  torch.float64\n",
      "short_points:  torch.int16\n"
     ]
    }
   ],
   "source": [
    "print('double_points: ', double_points.dtype)\n",
    "print('short_points: ', short_points.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ce2e81a3-c77e-4d50-a8aa-633ed3259d3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "double_points:  torch.float64\n",
      "short_points:  torch.int16\n",
      "uint_points:  torch.uint8\n",
      "bool_points:  torch.bool\n"
     ]
    }
   ],
   "source": [
    "double_points = torch.zeros(10, 2).double()\n",
    "short_points = torch.ones(10, 2).short()\n",
    "print('double_points: ', double_points.dtype)\n",
    "print('short_points: ', short_points.dtype)\n",
    "\n",
    "uint_points = torch.zeros(2, 2).to(torch.uint8)\n",
    "bool_points = torch.zeros(1, 2).to(torch.bool)\n",
    "print('uint_points: ', uint_points.dtype)\n",
    "print('bool_points: ', bool_points.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4821d3b0-80bf-4314-824b-4d465553aab3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 4.0\n",
      " 1.0\n",
      " 5.0\n",
      " 3.0\n",
      " 2.0\n",
      " 1.0\n",
      "[torch.storage.TypedStorage(dtype=torch.float32, device=cpu) of size 6]\n",
      "4.0\n",
      "1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4646/372007168.py:2: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  print(points.storage())\n"
     ]
    }
   ],
   "source": [
    "points = torch.tensor([[4.0, 1.0], [5.0, 3.0], [2.0, 1.0]])\n",
    "print(points.storage())\n",
    "\n",
    "points_storage = points.storage()\n",
    "print(points_storage[0])\n",
    "print(points.storage()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3e8286a9-580f-4570-9bac-4a3e59c2dfc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 2.0\n",
      " 1.0\n",
      " 5.0\n",
      " 3.0\n",
      " 2.0\n",
      " 1.0\n",
      "[torch.storage.TypedStorage(dtype=torch.float32, device=cpu) of size 6]\n",
      "tensor([[2., 1.],\n",
      "        [5., 3.],\n",
      "        [2., 1.]])\n"
     ]
    }
   ],
   "source": [
    "points_storage[0] = 2.0\n",
    "print(points_storage)\n",
    "print(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "185d7938-0da6-4dbc-8f8c-7a967c59abd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5., 3.])\n",
      "points_shape:  torch.Size([2])\n",
      "second_point_shape:  torch.Size([2])\n",
      "points_stride:  (2, 1)\n",
      "second_point_stride:  (1,)\n",
      "points_offset:  0\n",
      "second_point_offset:  2\n",
      "points_storage: \n",
      "  4.0\n",
      " 1.0\n",
      " 5.0\n",
      " 3.0\n",
      " 2.0\n",
      " 1.0\n",
      "[torch.storage.TypedStorage(dtype=torch.float32, device=cpu) of size 6]\n",
      "second_point_storage:\n",
      "  4.0\n",
      " 1.0\n",
      " 5.0\n",
      " 3.0\n",
      " 2.0\n",
      " 1.0\n",
      "[torch.storage.TypedStorage(dtype=torch.float32, device=cpu) of size 6]\n"
     ]
    }
   ],
   "source": [
    "points = torch.tensor([[4.0, 1.0], [5.0, 3.0], [2.0, 1.0]])\n",
    "second_point = points[1]\n",
    "print(second_point)\n",
    "\n",
    "print(\"points_shape: \", second_point.shape)\n",
    "print(\"second_point_shape: \", second_point.shape)\n",
    "\n",
    "print(\"points_stride: \", points.stride())\n",
    "print(\"second_point_stride: \", second_point.stride())\n",
    "\n",
    "print(\"points_offset: \", points.storage_offset())\n",
    "print(\"second_point_offset: \", second_point.storage_offset())\n",
    "\n",
    "print(\"points_storage: \\n\", points.storage())\n",
    "print(\"second_point_storage:\\n\", second_point.storage())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d7c05334-6324-4fc5-8021-27b9f847ceeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "points: \n",
      " tensor([[4., 1.],\n",
      "        [5., 3.],\n",
      "        [2., 1.]])\n",
      "second_point: \n",
      " tensor([5., 3.])\n",
      "modified_second_point: \n",
      " tensor([10.,  3.])\n",
      "confirm_points: \n",
      " tensor([[ 4.,  1.],\n",
      "        [10.,  3.],\n",
      "        [ 2.,  1.]])\n"
     ]
    }
   ],
   "source": [
    "points = torch.tensor([[4.0, 1.0], [5.0, 3.0], [2.0, 1.0]])\n",
    "print(\"points: \\n\", points)\n",
    "second_point = points[1]\n",
    "\n",
    "print(\"second_point: \\n\", second_point)\n",
    "second_point[0] = 10.0\n",
    "\n",
    "print(\"modified_second_point: \\n\", second_point)\n",
    "print(\"confirm_points: \\n\", points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "26faf17d-e097-400e-b337-a87c2744c9ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confirm_points: \n",
      " tensor([[4., 1.],\n",
      "        [5., 3.],\n",
      "        [2., 1.]])\n",
      "points_storage: \n",
      "  4.0\n",
      " 1.0\n",
      " 5.0\n",
      " 3.0\n",
      " 2.0\n",
      " 1.0\n",
      "[torch.storage.TypedStorage(dtype=torch.float32, device=cpu) of size 6]\n",
      "second_point_storage: \n",
      " 4.0\n",
      " 1.0\n",
      " 10.0\n",
      " 3.0\n",
      " 2.0\n",
      " 1.0\n",
      "[torch.storage.TypedStorage(dtype=torch.float32, device=cpu) of size 6]\n"
     ]
    }
   ],
   "source": [
    "points = torch.tensor([[4.0, 1.0], [5.0, 3.0], [2.0, 1.0]])\n",
    "secod_point = points[1].clone()\n",
    "second_point[0] = 10.0\n",
    "print(\"confirm_points: \\n\", points)\n",
    "print(\"points_storage: \\n\", points.storage())\n",
    "print(\"second_point_storage: \\n\", second_point.storage())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1106e80d-867f-47f6-8cd5-b92f65ac63fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "points_gpu = torch.tensor([[4.0, 1.0], [5.0, 3.0], [2.0, 1.0]], device=\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "65aa2b40-a260-4635-88c5-b878182a913e",
   "metadata": {},
   "outputs": [],
   "source": [
    "points = torch.tensor([[4.0, 1.0], [5.0, 3.0], [2.0, 1.0]])\n",
    "points_gpu = points.to(device=\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7e33a206-c38b-44fe-a44e-acc7d888cd17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "points_cpu: \n",
      " tensor([[20.,  8.],\n",
      "        [24., 16.],\n",
      "        [12.,  8.]])\n"
     ]
    }
   ],
   "source": [
    "points = 2 * points # CPU上で計算\n",
    "points_gpu = 2 * points.to(device=\"cuda\") # GPU上で計算\n",
    "points_gpu = points_gpu + 4\n",
    "points_cpu = points_gpu.to(device=\"cpu\")\n",
    "print(\"points_cpu: \\n\", points_cpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b76feffd-1d3e-4ad1-b261-3f1fe9dc5087",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(187, 270, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4646/892193373.py:3: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
      "  img_arr = imageio.imread(\"cat.jpeg\")\n"
     ]
    }
   ],
   "source": [
    "import imageio\n",
    "\n",
    "img_arr = imageio.imread(\"cat.jpeg\")\n",
    "print(img_arr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c75f872f-87bd-4751-89e2-948bec065fda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 187, 270])\n"
     ]
    }
   ],
   "source": [
    "img = torch.from_numpy(img_arr)\n",
    "out = img.permute(2, 0, 1)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b4887f59-afd2-4274-b409-bd6d9bfacc0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 3, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "batch_size = 3\n",
    "batch = torch.zeros(batch_size, 3, 256, 256, dtype=torch.uint8)\n",
    "print(batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "79ca8840-0e3c-4307-9f0a-283a7997b211",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from torchvision.io import read_image\n",
    "import torchvision.transforms.functional as F\n",
    "\n",
    "data_dir = \"/home/ee/ee33045l/EE4_2F-pytorch\"\n",
    "filenames = [name for name in os.listdir(data_dir)\n",
    "            if os.path.splitext(name)[-1] == \".jpeg\"]\n",
    "for i, filename in enumerate(filenames):\n",
    "    image = read_image(os.path.join(data_dir, filename))\n",
    "    image_re = F.resize(img=image, size=(256, 256))\n",
    "    batch[i] = image_re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3d8f4577-755b-407d-bbdc-b3b940a5b583",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = batch.float()\n",
    "n_channels =  batch.shape[1]\n",
    "for c in range(n_channels):\n",
    "    mean = torch.mean(batch[:, c])\n",
    "    std = torch.std(batch[:, c])\n",
    "    batch[:, c] = (batch[:, c] - mean) / std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "93577aeb-2587-479b-9abb-32929ee31d27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8])\n",
      "サイズ:  torch.Size([9])\n",
      "オフセット:  0\n",
      "ストライド:  (1,)\n"
     ]
    }
   ],
   "source": [
    "# 4.1 (1)\n",
    "import torch\n",
    "\n",
    "# list(range(9))からテンソルを作成\n",
    "a = torch.tensor(list(range(9)))\n",
    "print(a)\n",
    "\n",
    "# サイズ\n",
    "print(\"サイズ: \", a.shape)\n",
    "\n",
    "# オフセット\n",
    "print(\"オフセット: \", a.storage_offset())\n",
    "\n",
    "# ストライドを確認\n",
    "print(\"ストライド: \", a.stride())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "01d84906-3120-412c-be3f-a7189c3b1a47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 1, 2],\n",
      "        [3, 4, 5],\n",
      "        [6, 7, 8]])\n",
      "viewにはテンソルのサイズを変更する働きがある\n"
     ]
    }
   ],
   "source": [
    "# 4.1 (2)\n",
    "b = a.view(3, 3)\n",
    "print(b)\n",
    "print(\"viewにはテンソルのサイズを変更する働きがある\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "694499e5-52a8-4241-b93e-1f20bd8bd610",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8]) tensor([[0, 1, 2],\n",
      "        [3, 4, 5],\n",
      "        [6, 7, 8]])\n",
      "aのポインタ:  94694598468864\n",
      "bのポインタ:  94694598468864\n",
      "aとbは同じストレージを利用している！\n"
     ]
    }
   ],
   "source": [
    "# 4.1 (3)\n",
    "print(a, b)\n",
    "\n",
    "print(\"aのポインタ: \", a.data_ptr())\n",
    "print(\"bのポインタ: \", b.data_ptr())\n",
    "\n",
    "if a.data_ptr() ==  b.data_ptr():\n",
    "    print(\"aとbは同じストレージを利用している！\")\n",
    "else:\n",
    "    print(\"aとbは違うストレージを使用している!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "092df0be-61d4-42d9-8cb8-41ad1c2b3288",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4, 5],\n",
      "        [7, 8]])\n",
      "サイズ:  torch.Size([2, 2])\n",
      "オフセット:  4\n",
      "ストライド:  (3, 1)\n"
     ]
    }
   ],
   "source": [
    "# 4.1 (4)\n",
    "c = b[1:, 1:]\n",
    "print(c)\n",
    "print(\"サイズ: \", c.shape)\n",
    "print(\"オフセット: \", c.storage_offset())\n",
    "print(\"ストライド: \", c.stride())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dfeaecb2-7330-4006-852c-c1f5c43ef1b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "赤色明るさ: 42.967140255009106\n",
      "青色明るさ: 48.183069333333336\n",
      "緑色明るさ: 38.95169184414727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4646/2522578713.py:6: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
      "  red_img = imageio.imread(\"/home/ee/ee33045l/EE4_2F-pytorch/4-2/redrose.jpeg\")\n",
      "/tmp/ipykernel_4646/2522578713.py:7: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
      "  blue_img = imageio.imread(\"/home/ee/ee33045l/EE4_2F-pytorch/4-2/bluerose.jpeg\")\n",
      "/tmp/ipykernel_4646/2522578713.py:8: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
      "  green_img = imageio.imread(\"/home/ee/ee33045l/EE4_2F-pytorch/4-2/greenrose.jpeg\")\n"
     ]
    }
   ],
   "source": [
    "# 4.2 (1), (2), (3)\n",
    "import imageio\n",
    "\n",
    "data_dir = \"/home/ee/ee33045l/EE4_2F-pytorch/4-2/redrose/jpeg\"\n",
    "\n",
    "red_img = imageio.imread(\"/home/ee/ee33045l/EE4_2F-pytorch/4-2/redrose.jpeg\")\n",
    "blue_img = imageio.imread(\"/home/ee/ee33045l/EE4_2F-pytorch/4-2/bluerose.jpeg\")\n",
    "green_img = imageio.imread(\"/home/ee/ee33045l/EE4_2F-pytorch/4-2/greenrose.jpeg\")\n",
    "\n",
    "print(\"赤色明るさ:\", red_img.mean())\n",
    "print(\"青色明るさ:\", blue_img.mean())\n",
    "print(\"緑色明るさ:\", green_img.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6a6e719d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 赤色明るさ :  tensor(42.9671)\n",
      " 青色明るさ :  tensor(48.1831)\n",
      " 緑色明るさ :  tensor(38.9517)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7c/s01vmy5n6s13cj9wyd5ggsgm0000gn/T/ipykernel_35428/686392741.py:4: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
      "  red_img = imageio.imread(\"./4-2/redrose.jpeg\")\n",
      "/var/folders/7c/s01vmy5n6s13cj9wyd5ggsgm0000gn/T/ipykernel_35428/686392741.py:5: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
      "  blue_img = imageio.imread(\"./4-2/bluerose.jpeg\")\n",
      "/var/folders/7c/s01vmy5n6s13cj9wyd5ggsgm0000gn/T/ipykernel_35428/686392741.py:6: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
      "  green_img = imageio.imread(\"./4-2/greenrose.jpeg\")\n"
     ]
    }
   ],
   "source": [
    "import imageio\n",
    "import torch\n",
    "\n",
    "red_img = imageio.imread(\"./4-2/redrose.jpeg\")\n",
    "blue_img = imageio.imread(\"./4-2/bluerose.jpeg\")\n",
    "green_img = imageio.imread(\"./4-2/greenrose.jpeg\")\n",
    "\n",
    "red_tensor = torch.tensor(red_img, dtype=torch.float32)\n",
    "blue_tensor = torch.tensor(blue_img, dtype=torch.float32)\n",
    "green_tensor = torch.tensor(green_img, dtype=torch.float32)\n",
    "\n",
    "print(\" 赤色明るさ : \", red_tensor.mean())\n",
    "print(\" 青色明るさ : \", blue_tensor.mean())\n",
    "print(\" 緑色明るさ : \", green_tensor.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6f6c8d21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[R, G, B]の順で出力される。\n",
      "赤の画像\n",
      "[tensor(71.5677), tensor(21.9460), tensor(35.3877)]\n",
      "-----\n",
      "青の画像\n",
      "[tensor(39.5279), tensor(33.9923), tensor(71.0290)]\n",
      "-----\n",
      "緑の画像\n",
      "[tensor(22.2641), tensor(55.6354), tensor(38.9556)]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "red_image_mean = [red_tensor[:, :, 0].mean(), red_tensor[:, :, 1].mean(), red_tensor[:, :, 2].mean()]\n",
    "blue_image_mean = [blue_tensor[:, :, 0].mean(), blue_tensor[:, :, 1].mean(), blue_tensor[:, :, 2].mean()]\n",
    "green_image_mean = [green_tensor[:, :, 0].mean(), green_tensor[:, :, 1].mean(), green_tensor[:, :, 2].mean()]\n",
    "\n",
    "print(\"[R, G, B]の順で出力される。\")\n",
    "print(\"赤の画像\")\n",
    "print(red_image_mean)\n",
    "print(\"-----\")\n",
    "\n",
    "print(\"青の画像\")\n",
    "print(blue_image_mean)\n",
    "print(\"-----\")\n",
    "\n",
    "print(\"緑の画像\")\n",
    "print(green_image_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1276063a-8dba-4176-9a50-611c01123773",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[R, G, B]の順で出力される。\n",
      "赤の画像\n",
      "[71.56767014406358, 21.946030799801292, 35.38771982116244]\n",
      "-----\n",
      "青の画像\n",
      "[39.527888, 33.992276, 71.029044]\n",
      "-----\n",
      "緑の画像\n",
      "[22.264110946012877, 55.63538261515602, 38.955581971272906]\n"
     ]
    }
   ],
   "source": [
    "# 4.2\n",
    "import torch\n",
    "\n",
    "red_image_mean = [red_img[:, :, 0].mean(), red_img[:, :, 1].mean(), red_img[:, :, 2].mean()]\n",
    "blue_image_mean = [blue_img[:, :, 0].mean(), blue_img[:, :, 1].mean(), blue_img[:, :, 2].mean()]\n",
    "green_image_mean = [green_img[:, :, 0].mean(), green_img[:, :, 1].mean(), green_img[:, :, 2].mean()]\n",
    "\n",
    "print(\"[R, G, B]の順で出力される。\")\n",
    "print(\"赤の画像\")\n",
    "print(red_image_mean)\n",
    "print(\"-----\")\n",
    "\n",
    "print(\"青の画像\")\n",
    "print(blue_image_mean)\n",
    "print(\"-----\")\n",
    "\n",
    "print(\"緑の画像\")\n",
    "print(green_image_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d38b015-79c2-4b14-8355-7ffe3d09236f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
